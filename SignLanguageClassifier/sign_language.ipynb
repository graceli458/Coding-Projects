{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5psZbp9VJifm"
   },
   "source": [
    "uni # TODO: Replace this with your UNI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "385e43a763cf2a2e696526612151db7c079f8909",
    "colab_type": "text",
    "id": "_KSFigbQx3ZB"
   },
   "source": [
    "# MNIST Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bbcbb713210c674a54142d4ade11072985c94754",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oYcaXwrdx3ZC",
    "outputId": "5a1bbc8f-7b1f-4485-bc16-f908dce8f0b6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.utils  import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0c3SrV8MQqWU"
   },
   "outputs": [],
   "source": [
    "class SignLanguage:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "        self.data = {\n",
    "            \"train\": None,\n",
    "            \"test\" : None\n",
    "        }\n",
    "        self.create_model()\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a CNN model and save it to self.model\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Create a Sequential model\n",
    "        model = Sequential() \n",
    "            \n",
    "        # TODO: Compile the model with categorical_crossentropy\n",
    "        model.compile('adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def prepare_data(self, images, labels):\n",
    "        \"\"\"\n",
    "        Use this method to normalize the dataset and split it into train/test.\n",
    "        Save your data in self.data[\"train\"] and self.data[\"test\"] as a tuple\n",
    "        of (images, labels)\n",
    "        \n",
    "        :param images numpy array of size (num_examples, 28*28)\n",
    "        :param labels numpy array of size (num_examples, )\n",
    "        \"\"\"\n",
    "        # TODO : split into training and validation set\n",
    "        # TODO : reshape each example into a 2D image (28, 28, 1)\n",
    "        \n",
    "        self.data = {\n",
    "            \"train\": None, # (x_train, y_train)\n",
    "            \"test\" : None, # (x_test, y_test)\n",
    "        }\n",
    "    \n",
    "    def train(self, batch_size:int=128, epochs:int=50, verbose:int=1):\n",
    "        \"\"\"\n",
    "        Use model.fit() to train your model. Make sure to return the history for a neat visualization.\n",
    "        \n",
    "        :param batch_size The batch size to use for training\n",
    "        :param epochs     Number of epochs to use for training\n",
    "        :param verbose    Whether or not to print training output\n",
    "        \"\"\"\n",
    "        \n",
    "        history = None\n",
    "        return history\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Use the trained model to predict labels for test data.\n",
    "        \n",
    "        :param data: numpy array of test images\n",
    "        :return a numpy array of test labels. array size = (num_examples, )\n",
    "        \"\"\"\n",
    "        \n",
    "        # Don't forget to normalize the data in the same way as training data\n",
    "        # self.model.predict() and np.argmax( , axis=1) might help\n",
    "        \n",
    "        return np.zeros(data.shape[0])\n",
    "    \n",
    "    def visualize_data(self, data):\n",
    "        \"\"\"\n",
    "        Visualizing the hand gestures\n",
    "        \n",
    "        :param data: numpy array of images\n",
    "        \"\"\"\n",
    "        if data is None: return\n",
    "        \n",
    "        nrows, ncols = 5, 5\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(10, 10), sharex=True, sharey=True)\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                axs[i][j].imshow(data[0][i*ncols+j].reshape(28, 28), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_accuracy(self, history):\n",
    "        \"\"\"\n",
    "        Plots out the accuracy measures given a keras history object\n",
    "        \n",
    "        :param history: return value from model.fit()\n",
    "        \"\"\"\n",
    "        if history is None: return\n",
    "        \n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.legend(['train','test'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sFQekntgZqD"
   },
   "source": [
    "# Grading Script\n",
    "\n",
    "Do NOT modify this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784) (27455,) (7172, 784) (7172,)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test  = pd.read_csv('test.csv')\n",
    "\n",
    "    train_labels, test_labels = train['label'].values, test['label'].values\n",
    "    train.drop('label', axis=1, inplace=True)\n",
    "    test.drop('label', axis=1, inplace=True)\n",
    "\n",
    "    num_classes = test_labels.max() + 1\n",
    "    train_images, test_images = train.values, test.values\n",
    "\n",
    "    print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(len(test_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 20:02:43.786583: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-07 20:02:43.786715: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    my_model = SignLanguage()\n",
    "    my_model.prepare_data(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    my_model.visualize_data(my_model.data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    history = my_model.train(epochs=30, verbose=1)\n",
    "    my_model.visualize_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SSthbsGxm1-z",
    "outputId": "2a44f8d5-ff51-4071-a4c9-ddb14d01dc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04615170105967652\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    y_pred = my_model.predict(test_images)\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST-sign-language.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
