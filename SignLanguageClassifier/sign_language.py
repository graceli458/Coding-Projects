# -*- coding: utf-8 -*-
"""sign_language.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19prU6Z77Khkzwh6P1sSPH6taDYNH0k0Q

Grace Li - gl2676

# MNIST Sign Language
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics         import accuracy_score
from sklearn.model_selection import train_test_split

import keras
from keras.utils  import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout

# more load?
import keras
from keras import layers

class SignLanguage:
    def __init__(self):
        self.model = None

        self.data = {
            "train": None,
            "test" : None
        }
        self.create_model()

    def create_model(self):
        """
        Create a CNN model and save it to self.model
        """

        # TODO: Create a Sequential model

        #input = image ->
        # attempt 1
        model = Sequential()
        model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        model.add(MaxPooling2D(2, 2))
        model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        model.add(MaxPooling2D(2, 2))
        model.add(Flatten())
        model.add(Dropout(rate=0.2))
        model.add(Dense(25, activation="softmax"))

        # attempt 2
        # model = Sequential()
        # model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        # model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        # model.add(MaxPooling2D(2, 2))
        # model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        # model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
        # model.add(MaxPooling2D(2, 2))
        # model.add(Flatten())
        # #model.add(Dropout(rate=0.2))
        # model.add(Dense(25, activation="softmax"))

        # TODO: Compile the model with categorical_crossentropy
        model.compile('adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

        self.model = model

    def prepare_data(self, images, labels):
        """
        Use this method to normalize the dataset and split it into train/test.
        Save your data in self.data["train"] and self.data["test"] as a tuple
        of (images, labels)

        :param images numpy array of size (num_examples, 28*28)
        :param labels numpy array of size (num_examples, )
        """
        # TODO : reshape each example into a 2D image (28, 28, 1)
        # reshape the images into 28 X 28
        # reshape the labels into one-hot encoding - vector for all zeros and 1 in index that it's supposed to be
        # standardize by dividing by 255 iterate thorugh element in images

        X = []
        for vector in images:
          X.append(np.reshape(vector/255.0, (28, 28, 1)))

        #reshape labels
        # min = 0; max = 24
        y = keras.utils.to_categorical(labels, num_classes=25)


        # TODO : split into training and validation set
        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # code fixed the length problem of just going train_test_split
        # finalObjects_train = list(zip(x_train, y_train))
        # shuffledImages_train = list(zip(*finalObjects_train))[0]
        # shuffledLabels_train = list(zip(*finalObjects_train))[1]

        # finalObjects_test = list(zip(x_test, y_test))
        # shuffledImages_test = list(zip(*finalObjects_test))[0]
        # shuffledImages_test = list(zip(*finalObjects_test))[1]


        self.data = {
            "train": (np.array(x_train), np.array(y_train)),
            "test" : (np.array(x_test), np.array(y_test))
        }

    def train(self, batch_size:int=128, epochs:int=50, verbose:int=1):
        """
        Use model.fit() to train your model. Make sure to return the history for a neat visualization.

        :param batch_size The batch size to use for training
        :param epochs     Number of epochs to use for training
        :param verbose    Whether or not to print training output
        """

        # need to pass in X and Y
        # can also pass in validation data validation_data = self.data["test"] -> look it up

        history = self.model.fit(self.data["train"][0], self.data["train"][1], batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data = self.data["test"]) # validation_data = (self.data["test"][0],self.data["test"][1])
        return history

    def predict(self, data):
        """
        Use the trained model to predict labels for test data.

        :param data: numpy array of test images
        :return a numpy array of test labels. array size = (num_examples, )
        """

        # Don't forget to normalize the data in the same way as training data
        # self.model.predict() and np.argmax( , axis=1) might help

        # reshape data as well -> and divide by 255
        # call predict on the reshaped data -> reutrn value is a vector -> tkae argmax to get index of highest probability
        new = []
        for item in data:
          new.append(np.reshape(item/255.0, (28, 28, 1)))

        vector = self.model.predict(np.array(new))

        return np.argmax(vector, axis=1)

    def visualize_data(self, data):
        """
        Visualizing the hand gestures

        :param data: numpy array of images
        """
        if data is None: return

        nrows, ncols = 5, 5
        fig, axs = plt.subplots(nrows, ncols, figsize=(10, 10), sharex=True, sharey=True)
        plt.subplots_adjust(wspace=0, hspace=0)

        for i in range(nrows):
            for j in range(ncols):
                axs[i][j].imshow(data[0][i*ncols+j].reshape(28, 28), cmap='gray')
        plt.show()

    def visualize_accuracy(self, history):
        """
        Plots out the accuracy measures given a keras history object

        :param history: return value from model.fit()
        """
        if history is None: return

        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title("Accuracy")
        plt.xlabel('epoch')
        plt.ylabel('accuracy')
        plt.legend(['train','test'])
        plt.show()

"""# Grading Script

Do NOT modify this section
"""

if __name__=="__main__":
    train = pd.read_csv('train.csv')
    test  = pd.read_csv('test.csv')

    train_labels, test_labels = train['label'].values, test['label'].values
    train.drop('label', axis=1, inplace=True)
    test.drop('label', axis=1, inplace=True)

    num_classes = test_labels.max() + 1
    train_images, test_images = train.values, test.values

    print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)

if __name__=="__main__":
    my_model = SignLanguage()
    my_model.prepare_data(train_images, train_labels)

if __name__=="__main__":
    my_model.visualize_data(my_model.data["train"])

if __name__=="__main__":
    history = my_model.train(epochs=30, verbose=1)
    my_model.visualize_accuracy(history)

if __name__=="__main__":
    y_pred = my_model.predict(test_images)
    accuracy = accuracy_score(test_labels, y_pred)
    print(accuracy)